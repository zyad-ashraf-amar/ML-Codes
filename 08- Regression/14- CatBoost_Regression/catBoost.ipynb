{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Regression\n",
    "CatBoost (Categorical Boosting) is a gradient boosting algorithm developed by Yandex. It is designed to handle categorical features directly, without the need for extensive preprocessing. CatBoost builds on the principles of decision trees and gradient boosting to provide high accuracy and efficient performance.\n",
    "\n",
    "## Advantages:\n",
    "- Handles Categorical Features: Directly processes categorical features without the need for extensive preprocessing like one-hot encoding.\n",
    "- Robustness to Overfitting: Includes built-in mechanisms to reduce overfitting.\n",
    "- High Performance: Often provides superior performance and accuracy compared to other gradient boosting methods.\n",
    "- Ease of Use: Requires minimal data preprocessing and parameter tuning.\n",
    "- GPU Support: Can leverage GPU for faster training.\n",
    "\n",
    "## Disadvantages:\n",
    "- Complexity: Can be more complex to understand and interpret compared to simpler models.\n",
    "- Computationally Intensive: Training can be computationally intensive, especially with large datasets.\n",
    "- Parameter Tuning: While less intensive than some methods, it still requires careful tuning for optimal performance.\n",
    "\n",
    "### Use Cases:\n",
    "- Finance: Credit scoring, risk assessment, stock price prediction.\n",
    "- Healthcare: Disease progression prediction, patient risk stratification.\n",
    "- Marketing: Customer segmentation, response modeling, sales forecasting.\n",
    "- E-commerce: Recommendation systems, customer churn prediction.\n",
    "\n",
    "## Scaling\n",
    "- Scaling: No, scaling is not necessary for CatBoost because it handles feature scaling internally.\n",
    "\n",
    "## Encoding\n",
    "- Encoding: No, CatBoost handles categorical features natively and does not require manual encoding like one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset (replace with your data)\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': ['A', 'B', 'A', 'B', 'C'],\n",
    "    'target': [10, 20, 15, 25, 30]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Preprocessing for categorical features\n",
    "categorical_features = ['feature2']\n",
    "numeric_features = ['feature1']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_boost = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300, 500, 1000],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'bagging_temperature': [0, 0.5, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300, 500, 1000],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'bagging_temperature': [0, 0.5, 1, 1.5, 2],\n",
    "    'random_strength': [0, 0.5, 1, 1.5, 2],\n",
    "    'border_count': [32, 64, 128, 254],\n",
    "    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "}\n",
    "\n",
    "# Ensure that the number of splits in cross-validation is less than the number of samples\n",
    "cv_splits = min(len(y_train), 3)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(cat_boost, param_grid, cv=cv_splits, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train,  cat_features=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_boost = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "# Parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'iterations': np.arange(100, 1001, 100),\n",
    "    'depth': np.arange(4, 11),\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "    'l2_leaf_reg': np.arange(1, 10, 1),\n",
    "    'bagging_temperature': np.linspace(0, 2, 20)\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'iterations': np.arange(100, 1001, 100),\n",
    "    'depth': np.arange(4, 11),\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "    'l2_leaf_reg': np.arange(1, 10, 1),\n",
    "    'bagging_temperature': np.linspace(0, 2, 20),\n",
    "    'random_strength': np.linspace(0, 2, 20),\n",
    "    'border_count': np.arange(32, 255, 32),\n",
    "    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "}\n",
    "\n",
    "# Ensure that the number of splits in cross-validation is less than the number of samples\n",
    "cv_splits = min(len(y_train), 3)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(cat_boost, param_dist, n_iter=200, cv=cv_splits, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train,  cat_features=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train cat_boost without search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
