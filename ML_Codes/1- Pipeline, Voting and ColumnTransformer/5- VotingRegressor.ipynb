{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingRegressor \n",
    "The VotingRegressor is a meta-estimator in machine learning, part of the ensemble module in Scikit-learn. It combines the predictions from multiple regression models to form a final prediction by averaging their predictions. This method can lead to better performance compared to using a single model, as it leverages the strengths of various models to make more accurate predictions.\n",
    "\n",
    "# How It Works\n",
    "- Model Initialization: Multiple regression models are initialized and trained on the same dataset.\n",
    "- Fitting the Ensemble: Each model is fitted to the data.\n",
    "- Predicting: For new data, each model makes a prediction, and the final prediction is obtained by averaging the predictions of all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Generate a simple regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base models\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor()\n",
    "\n",
    "# Combine the models into a Voting Regressor\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('dt', model2)])\n",
    "\n",
    "# Train the Voting Regressor\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = voting_regressor.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Load a more complex dataset\n",
    "data = load_boston()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base models\n",
    "model1 = LinearRegression()\n",
    "model2 = Ridge(alpha=1.0)\n",
    "model3 = DecisionTreeRegressor()\n",
    "model4 = KNeighborsRegressor()\n",
    "\n",
    "# Combine the models into a Voting Regressor\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('ridge', model2), ('dt', model3), ('knn', model4)])\n",
    "\n",
    "# Train the Voting Regressor\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = voting_regressor.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Complex Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load a very complex dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base models\n",
    "model1 = LinearRegression()\n",
    "model2 = Ridge(alpha=1.0)\n",
    "model3 = DecisionTreeRegressor()\n",
    "model4 = KNeighborsRegressor()\n",
    "model5 = SVR()\n",
    "\n",
    "# Combine the models into a Voting Regressor\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('ridge', model2), ('dt', model3), ('knn', model4), ('svr', model5)])\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'svr__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=voting_regressor, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Train the Voting Regressor with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression, load_boston, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor()\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('dt', model2)])\n",
    "\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "predictions = voting_regressor.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(voting_regressor, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = Ridge(alpha=1.0)\n",
    "model3 = DecisionTreeRegressor()\n",
    "model4 = KNeighborsRegressor()\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('ridge', model2), ('dt', model3), ('knn', model4)])\n",
    "\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "predictions = voting_regressor.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(voting_regressor, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_very_complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = Ridge(alpha=1.0)\n",
    "model3 = DecisionTreeRegressor()\n",
    "model4 = KNeighborsRegressor()\n",
    "model5 = SVR()\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', model1), ('ridge', model2), ('dt', model3), ('knn', model4), ('svr', model5)])\n",
    "\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'svr__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=voting_regressor, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "predictions = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(grid_search.best_estimator_, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingRegressor with BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import VotingRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Load the California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models wrapped with BaggingRegressor\n",
    "model1 = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
    "model2 = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=10, random_state=42)\n",
    "model3 = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=10, random_state=42)\n",
    "\n",
    "# Combine the models into a VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[('bag_dt', model1), ('bag_lr', model2), ('bag_knn', model3)])\n",
    "\n",
    "# Train the VotingRegressor\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using cross-validation\n",
    "scores = cross_val_score(voting_regressor, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores for VotingRegressor with BaggingRegressor:\", scores)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = voting_regressor.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use BaggingRegressor with different base regressors (DecisionTree, LinearRegression, KNeighbors).\n",
    "- These bagged models are combined into a VotingRegressor.\n",
    "- We evaluate the regressor using cross-validation and print the predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingRegressor with VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor, VotingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Load the California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models for VotingRegressor\n",
    "model1 = DecisionTreeRegressor()\n",
    "model2 = LinearRegression()\n",
    "model3 = KNeighborsRegressor()\n",
    "\n",
    "# Combine the models into a VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[('dt', model1), ('lr', model2), ('knn', model3)])\n",
    "\n",
    "# Use the VotingRegressor as the base estimator for BaggingRegressor\n",
    "bagging_regressor = BaggingRegressor(base_estimator=voting_regressor, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingRegressor\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using cross-validation\n",
    "scores = cross_val_score(bagging_regressor, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores for BaggingRegressor with VotingRegressor:\", scores)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = bagging_regressor.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create a VotingRegressor using DecisionTreeRegressor, LinearRegression, and KNeighborsRegressor.\n",
    "- We then use this VotingRegressor as the base estimator for a BaggingRegressor.\n",
    "- We train the BaggingRegressor, evaluate its performance using cross-validation, and make predictions on the test set."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
