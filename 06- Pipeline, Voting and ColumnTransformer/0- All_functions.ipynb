{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "- Pipeline\n",
    "- make_pipeline\n",
    "- VotingClassifier\n",
    "- ColumnTransformer\n",
    "- make_column_transformer\n",
    "- make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_transformer, make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "# Define the classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "clf2 = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Create the VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', clf1),\n",
    "        ('lr', clf2),\n",
    "        ('svc', clf3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Create the final pipeline\n",
    "pipeline = make_pipeline(preprocessor, voting_clf)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another dataset with customizing any of the steps in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Prepare the dataset\n",
    "# Drop unnecessary columns and rows with missing target\n",
    "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "data = data.dropna(subset=['Survived'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns='Survived')\n",
    "y = data['Survived']\n",
    "\n",
    "# Fill missing values\n",
    "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_transformer, make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "# Define the classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "clf2 = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Create the VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', clf1),\n",
    "        ('lr', clf2),\n",
    "        ('svc', clf3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Create the final pipeline\n",
    "pipeline = make_pipeline(preprocessor, voting_clf)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor\n",
    "- Pipeline\n",
    "- make_pipeline\n",
    "- VotingRegressor \n",
    "- ColumnTransformer\n",
    "- make_column_transformer\n",
    "- make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Since the California housing dataset only has numerical features, we'll simulate a categorical column\n",
    "# Adding a synthetic categorical column for demonstration\n",
    "X_train['SyntheticCat'] = np.random.choice(['A', 'B', 'C'], size=X_train.shape[0])\n",
    "X_test['SyntheticCat'] = np.random.choice(['A', 'B', 'C'], size=X_test.shape[0])\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_transformer, make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "# Define the regressors\n",
    "reg1 = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "reg2 = LinearRegression()\n",
    "reg3 = SVR(kernel='rbf')\n",
    "\n",
    "# Create the VotingRegressor\n",
    "voting_reg = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', reg1),\n",
    "        ('lr', reg2),\n",
    "        ('svr', reg3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the final pipeline\n",
    "pipeline = make_pipeline(preprocessor, voting_reg)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another dataset with customizing any of the steps in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "\n",
    "# Simulate a categorical column for demonstration\n",
    "X['CHAS'] = X['CHAS'].astype(str)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_transformer, make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "# Define the regressors\n",
    "reg1 = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "reg2 = LinearRegression()\n",
    "reg3 = SVR(kernel='rbf')\n",
    "\n",
    "# Create the VotingRegressor\n",
    "voting_reg = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', reg1),\n",
    "        ('lr', reg2),\n",
    "        ('svr', reg3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the final pipeline\n",
    "pipeline = make_pipeline(preprocessor, voting_reg)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
