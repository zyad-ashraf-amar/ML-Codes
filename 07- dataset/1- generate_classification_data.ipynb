{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Function to generate a dataset\n",
    "def generate_dataset(n_samples, n_features, n_informative, n_redundant, n_clusters_per_class, class_sep, flip_y, random_state):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        n_redundant=n_redundant,\n",
    "        n_clusters_per_class=n_clusters_per_class,\n",
    "        class_sep=class_sep,\n",
    "        flip_y=flip_y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return pd.DataFrame(X), pd.Series(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple Dataset\n",
    "X_simple_class, y_simple_class = generate_dataset(\n",
    "    n_samples=1000,        # Number of samples\n",
    "    n_features=5,          # Total number of features\n",
    "    n_informative=3,       # Number of informative features\n",
    "    n_redundant=0,         # Number of redundant features\n",
    "    n_clusters_per_class=1,# Number of clusters per class\n",
    "    class_sep=1.0,         # Factor that multiplies the hypercube size for each class\n",
    "    flip_y=0.01,           # Fraction of samples whose class is assigned randomly\n",
    "    random_state=42        # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# # Save datasets to CSV files\n",
    "# X_simple_class.to_csv('X_simple_class.csv', index=False)\n",
    "# y_simple_class.to_csv('y_simple_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Complex Dataset\n",
    "X_complex_class, y_complex_class = generate_dataset(\n",
    "    n_samples=1000,        # Number of samples\n",
    "    n_features=10,         # Total number of features\n",
    "    n_informative=5,       # Number of informative features\n",
    "    n_redundant=2,         # Number of redundant features\n",
    "    n_clusters_per_class=2,# Number of clusters per class\n",
    "    class_sep=0.8,         # Factor that multiplies the hypercube size for each class\n",
    "    flip_y=0.05,           # Fraction of samples whose class is assigned randomly\n",
    "    random_state=42        # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# # Save datasets to CSV files\n",
    "# X_complex_class.to_csv('X_complex_class.csv', index=False)\n",
    "# y_complex_class.to_csv('y_complex_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Very Complex Dataset\n",
    "X_very_complex_class, y_very_complex_class = generate_dataset(\n",
    "    n_samples=1000,        # Number of samples\n",
    "    n_features=20,         # Total number of features\n",
    "    n_informative=10,      # Number of informative features\n",
    "    n_redundant=5,         # Number of redundant features\n",
    "    n_clusters_per_class=3,# Number of clusters per class\n",
    "    class_sep=0.5,         # Factor that multiplies the hypercube size for each class\n",
    "    flip_y=0.1,            # Fraction of samples whose class is assigned randomly\n",
    "    random_state=42        # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# # Save datasets to CSV files\n",
    "# X_very_complex_class.to_csv('X_very_complex_class.csv', index=False)\n",
    "# y_very_complex_class.to_csv('y_very_complex_class.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
