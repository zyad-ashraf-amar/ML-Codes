{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AdaBoost Classifier\n",
        "AdaBoost (Adaptive Boosting) is an ensemble learning technique that combines multiple weak classifiers to create a strong classifier. It works by iteratively training weak classifiers on different distributions of the data and then combining their predictions through a weighted majority vote.\n",
        "\n",
        "## Advantages:\n",
        "- Improved Accuracy: By combining weak learners, AdaBoost can significantly improve prediction accuracy.\n",
        "- Versatility: Can be used with various base classifiers.\n",
        "- Resistance to Overfitting: Less prone to overfitting compared to other models.\n",
        "- Simple and Fast: Easy to implement and relatively fast to train.\n",
        "\n",
        "## Disadvantages:\n",
        "- Sensitivity to Noisy Data: Performance can degrade with noisy data and outliers.\n",
        "- Computationally Intensive: Requires multiple iterations which can be computationally expensive.\n",
        "- Requires Careful Tuning: The choice of base classifier and its parameters significantly affect performance.\n",
        "\n",
        "## Use Case:\n",
        "- Image Recognition: Used for face detection and other image classification tasks.\n",
        "- Spam Detection: Helps in distinguishing between spam and non-spam emails.\n",
        "- Customer Churn Prediction: Predicts whether a customer will stop using a service.\n",
        "- Credit Scoring: Assesses the risk of lending money to potential borrowers.\n",
        "\n",
        "## Scaling (not necessary and necessary Depend on the models)\n",
        "AdaBoost itself does not require scaling, but it depends on the base estimator used. For example, SVMs require scaling, while decision trees do not.\n",
        "\n",
        "## Encoding (necessary)\n",
        "Categorical data must be encoded into numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_J-kYLncQQH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import uniform, loguniform\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.datasets import make_Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Breast_Cancer.csv')\n",
        "x = df.drop('diagnosis',axis=1)\n",
        "y = df['diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. AdaBoost with the Default Estimator (Decision Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the AdaBoost Regressor with default estimator (DecisionTreeClassifier)\n",
        "AdaBoost_clas = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__max_depth': [None, 10, 20, 30],\n",
        "    'estimator__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(AdaBoost_clas, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the AdaBoost Regressor with default estimator (DecisionTreeClassifier)\n",
        "AdaBoost_clas = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'estimator__min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(AdaBoost_clas, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Train the grid search\n",
        "random_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train AdaBoostClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "SHr_MnXkmaOp",
        "outputId": "c06c27bc-f2c5-46eb-ca87-9bb02a62cde3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10, min_samples_split=5),n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. AdaBoost with a Single Estimator (Support Vector Classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Create the AdaBoost Regressor with SVC\n",
        "AdaBoost_clas_SVC = AdaBoostClassifier(estimator=SVC(probability=True), random_state=42)\n",
        "\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__C': [0.1, 1, 10, 100],\n",
        "    'estimator__gamma': ['scale', 'auto'] + list(np.logspace(-9, 3, 13)),\n",
        "    'estimator__kernel': ['linear', 'poly', 'rbf']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(AdaBoost_clas_SVC, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create the AdaBoost Regressor with default estimator (DecisionTreeClassifier)\n",
        "AdaBoost_clas_SVC = AdaBoostClassifier(estimator=SVC(probability=True), random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__C': [0.1, 1, 10, 100],\n",
        "    'estimator__gamma': ['scale', 'auto'] + list(np.logspace(-9, 3, 13)),\n",
        "    'estimator__kernel': ['linear', 'poly', 'rbf']\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(AdaBoost_clas_SVC, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Train the grid search\n",
        "random_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train AdaBoostClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = AdaBoostClassifier(estimator=SVC(kernel='linear', gamma=1, C=100),n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. AdaBoost with Multiple Estimators (SVC, Decision Tree, GaussianNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the individual regressors without the Pipeline of scaler\n",
        "svc = SVC(probability=True)\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "gaussian_NB = GaussianNB()\n",
        "\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_regressor = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "# Create the AdaBoost Regressor with VotingClassifier\n",
        "AdaBoost_clas_voting = AdaBoostClassifier(estimator=voting_regressor, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__SVC__C': [0.1, 1, 10],\n",
        "    'estimator__SVC__gamma': [0.1, 0.5, 1],\n",
        "    'estimator__SVC__kernel': ['linear', 'poly', 'rbf'],\n",
        "    'estimator__decision_tree__max_depth': [None, 10, 20, 30],\n",
        "    'estimator__decision_tree__min_samples_split': [2, 5, 10],\n",
        "    'estimator__gaussian_NB__var_smoothing': np.logspace(-9, 0, 10)\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_voting = GridSearchCV(AdaBoost_clas_voting, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search_voting.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Create the individual classifiers\n",
        "svc = SVC(probability=True)\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "gaussian_NB = GaussianNB()\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "# Create the AdaBoostClassifier with VotingClassifier\n",
        "AdaBoost_clas_voting = AdaBoostClassifier(estimator=voting_classifier, algorithm='SAMME', random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__SVC__C': [0.1, 1, 10, 100],\n",
        "    'estimator__SVC__gamma': [0.1, 0.2, 0.5, 1.0],\n",
        "    'estimator__SVC__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'estimator__decision_tree__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'estimator__decision_tree__min_samples_split': [2, 5, 10, 15],\n",
        "    'estimator__gaussian_NB__var_smoothing': np.logspace(-9, 0, 10)\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search_voting = RandomizedSearchCV(AdaBoost_clas_voting, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Train the grid search\n",
        "random_search_voting.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train AdaBoostClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create the individual regressors without the Pipeline of scaler\n",
        "svc = SVC(kernel='linear', gamma=1, C=1)\n",
        "decision_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2)\n",
        "gaussian_NB = GaussianNB(var_smoothing=0.001)\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_regressor = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "\n",
        "model = AdaBoostClassifier(estimator=voting_regressor,n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
