{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier\n",
    "The VotingClassifier function in scikit-learn is an ensemble learning method that combines the predictions from multiple machine learning classifiers to improve the robustness and accuracy of the model. It can be configured to use either hard voting (majority rule voting) or soft voting (average of predicted probabilities).\n",
    "\n",
    "# How It Works\n",
    "- Initialize Individual Classifiers: Define the individual classifiers you want to use in the ensemble.\n",
    "- Create VotingClassifier: Combine the individual classifiers using VotingClassifier.\n",
    "- Fit the Ensemble Model: Train the ensemble model on the training data.\n",
    "- Make Predictions: Use the ensemble model to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define individual classifiers\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2)], voting='hard')\n",
    "\n",
    "# Fit ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression and DecisionTreeClassifier.\n",
    "- Demonstrates hard voting where the majority class is chosen as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "data = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define individual classifiers\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC(probability=True)  # Enable probability estimates for soft voting\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2), \n",
    "    ('svc', clf3)], voting='soft')\n",
    "\n",
    "# Fit ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression, DecisionTreeClassifier, and SVC.\n",
    "- Demonstrates soft voting where the average of predicted probabilities is used for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Complex Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define individual classifiers\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC(probability=True)  # Enable probability estimates for soft voting\n",
    "clf4 = RandomForestClassifier()\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2), \n",
    "    ('svc', clf3), \n",
    "    ('rf', clf4)], voting='soft')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'rf__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5)\n",
    "\n",
    "# Fit ensemble model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression, DecisionTreeClassifier, SVC, and RandomForestClassifier.\n",
    "- Integrates GridSearchCV to optimize parameters for each classifier in the ensemble.\n",
    "- Uses soft voting to average the predicted probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2)], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "self.assertEqual(len(predictions), len(y_test))\n",
    "print(f\"Simple Voting Classifier Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "\n",
    "scores = cross_val_score(voting_clf, data.data, data.target, cv=5)\n",
    "print(f\"Simple Voting Classifier Cross-Validation Scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression and DecisionTreeClassifier.\n",
    "- Tests if predictions match the length of the test data.\n",
    "- Evaluates the performance using cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2), \n",
    "    ('svc', clf3)], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "self.assertEqual(len(predictions), len(y_test))\n",
    "print(f\"Complex Voting Classifier Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "\n",
    "scores = cross_val_score(voting_clf, data.data, data.target, cv=5)\n",
    "print(f\"Complex Voting Classifier Cross-Validation Scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression, DecisionTreeClassifier, and SVC.\n",
    "- Tests if predictions match the length of the test data.\n",
    "- Evaluates the performance using cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_very_complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "clf4 = RandomForestClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2), \n",
    "    ('svc', clf3), \n",
    "    ('rf', clf4)], voting='soft')\n",
    "\n",
    "param_grid = {\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'rf__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "self.assertEqual(len(predictions), len(y_test))\n",
    "print(f\"Very Complex Voting Classifier Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "\n",
    "scores = cross_val_score(grid_search, data.data, data.target, cv=5)\n",
    "print(f\"Very Complex Voting Classifier Cross-Validation Scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses LogisticRegression, DecisionTreeClassifier, SVC, and RandomForestClassifier.\n",
    "- Integrates GridSearchCV to optimize parameters for each classifier in the ensemble.\n",
    "- Tests if predictions match the length of the test data.\n",
    "- Evaluates the performance using cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier with BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models wrapped with BaggingClassifier\n",
    "model1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "model2 = BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=10, random_state=42)\n",
    "model3 = BaggingClassifier(base_estimator=LogisticRegression(max_iter=200), n_estimators=10, random_state=42)\n",
    "\n",
    "# Combine the models into a VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=[('bag_dt', model1), ('bag_knn', model2), ('bag_lr', model3)], voting='soft')\n",
    "\n",
    "# Train the VotingClassifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using cross-validation\n",
    "scores = cross_val_score(voting_classifier, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores for VotingClassifier with BaggingClassifier:\", scores)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use BaggingClassifier with different base classifiers (DecisionTree, KNeighbors, LogisticRegression).\n",
    "- These bagged models are combined into a VotingClassifier.\n",
    "- We evaluate the classifier using cross-validation and print the predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingClassifier with VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models for VotingClassifier\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Combine the models into a VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=[('dt', model1), ('knn', model2), ('lr', model3)], voting='soft')\n",
    "\n",
    "# Use the VotingClassifier as the base estimator for BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=voting_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using cross-validation\n",
    "scores = cross_val_score(bagging_classifier, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores for BaggingClassifier with VotingClassifier:\", scores)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create a VotingClassifier using DecisionTreeClassifier, KNeighborsClassifier, and LogisticRegression.\n",
    "- We then use this VotingClassifier as the base estimator for a BaggingClassifier.\n",
    "- We train the BaggingClassifier, evaluate its performance using cross-validation, and make predictions on the test set."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
