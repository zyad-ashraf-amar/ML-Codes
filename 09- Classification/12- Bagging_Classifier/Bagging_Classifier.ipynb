{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bagging Classifier\n",
        "The Bagging Classifier (Bootstrap Aggregating) is an ensemble learning method that improves the stability and accuracy of machine learning algorithms by combining multiple models. It works by creating multiple subsets of the original dataset with replacement and training a base estimator on each subset. The final prediction is made by aggregating the predictions of all base estimators, typically through majority voting.\n",
        "\n",
        "## Advantages:\n",
        "- Reduced Overfitting: By averaging multiple models, Bagging reduces overfitting and variance.\n",
        "- Improved Accuracy: Combines multiple models to achieve higher accuracy compared to a single model.\n",
        "- Parallel Training: Base estimators can be trained in parallel, speeding up the training process.\n",
        "- Robustness: Works well with a variety of models and is robust to noisy data.\n",
        "\n",
        "## Disadvantages:\n",
        "- Increased Complexity: More complex and computationally intensive compared to using a single model.\n",
        "- Resource Intensive: Requires significant computational resources and memory, especially for large datasets.\n",
        "- Model Interpretability: The ensemble model is harder to interpret compared to a single decision tree or simpler model.\n",
        "\n",
        "## Use Case:\n",
        "- Finance: Fraud detection, credit scoring, and risk assessment.\n",
        "- Healthcare: Disease prediction and patient outcome analysis.\n",
        "- Marketing: Customer segmentation, churn prediction, and recommendation systems.\n",
        "- E-commerce: Product recommendation, inventory forecasting, and sales prediction.\n",
        "\n",
        "## Scaling (not necessary and necessary Depend on the models)\n",
        "Bagging does not require feature scaling because it is based on decision tree algorithms which are not sensitive to the scale of the features. However, if the base estimator requires scaling (e.g., SVM), then scaling is necessary.\n",
        "\n",
        "## Encoding (necessary)\n",
        "Categorical data must be encoded into numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_J-kYLncQQH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import uniform, loguniform\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.datasets import make_regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Breast_Cancer.csv')\n",
        "x = df.drop('diagnosis',axis=1)\n",
        "y = df['diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Bagging with the Default Estimator (Decision Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the Bagging Regressor with default estimator (DecisionTreeClassifier)\n",
        "bagging_clas = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__max_depth': [None, 10, 20, 30],\n",
        "    'estimator__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(bagging_clas, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the Bagging Regressor with default estimator (DecisionTreeClassifier)\n",
        "bagging_clas = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'estimator__min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(bagging_clas, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Train the grid search\n",
        "random_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train BaggingClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "SHr_MnXkmaOp",
        "outputId": "c06c27bc-f2c5-46eb-ca87-9bb02a62cde3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10, min_samples_split=5),n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Bagging with a Single Estimator (Support Vector Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Create the Bagging Regressor with SVC\n",
        "bagging_clas_SVC = BaggingClassifier(estimator=SVC(), random_state=42)\n",
        "\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__C': [0.1, 1, 10, 100],\n",
        "    'estimator__gamma': ['scale', 'auto'] + list(np.logspace(-9, 3, 13)),\n",
        "    'estimator__kernel': ['linear', 'poly', 'rbf']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(bagging_clas_SVC, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create the Bagging Regressor with default estimator (DecisionTreeClassifier)\n",
        "bagging_clas_SVC = BaggingClassifier(estimator=SVC(), random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__C': [0.1, 1, 10, 100],\n",
        "    'estimator__gamma': ['scale', 'auto'] + list(np.logspace(-9, 3, 13)),\n",
        "    'estimator__kernel': ['linear', 'poly', 'rbf']\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(bagging_clas_SVC, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Train the grid search\n",
        "random_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train BaggingClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = BaggingClassifier(estimator=SVC(kernel='linear', gamma=1, C=100),n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Bagging with Multiple Estimators (SVC, Decision Tree, GaussianNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the individual regressors without the Pipeline of scaler\n",
        "svc = SVC()\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "gaussian_NB = GaussianNB()\n",
        "\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_regressor = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "# Create the Bagging Regressor with VotingClassifier\n",
        "bagging_clas_voting = BaggingClassifier(estimator=voting_regressor, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__SVC__C': [0.1, 1, 10],\n",
        "    'estimator__SVC__gamma': [0.1, 0.5, 1],\n",
        "    'estimator__SVC__kernel': ['linear', 'poly', 'rbf'],\n",
        "    'estimator__decision_tree__max_depth': [None, 10, 20, 30],\n",
        "    'estimator__decision_tree__min_samples_split': [2, 5, 10],\n",
        "    'estimator__gaussian_NB__var_smoothing': np.logspace(-9, 0, 10)\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_voting = GridSearchCV(bagging_clas_voting, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the grid search\n",
        "grid_search_voting.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", grid_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model with best hyperparameters\n",
        "model = grid_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create the individual regressors without the Pipeline of scaler\n",
        "svc = SVC()\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "gaussian_NB = GaussianNB()\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_regressor = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "# Create the Bagging Regressor with VotingClassifier\n",
        "bagging_clas_voting = BaggingClassifier(estimator=voting_regressor, random_state=42)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'estimator__SVC__C': [0.1, 1, 10, 100],\n",
        "    'estimator__SVC__gamma': [0.1, 0.2, 0.5, 1.0],\n",
        "    'estimator__SVC__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'estimator__decision_tree__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'estimator__decision_tree__min_samples_split': [2, 5, 10, 15],\n",
        "    'estimator__gaussian_NB__var_smoothing': np.logspace(-9, 0, 10)\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search_voting = RandomizedSearchCV(bagging_clas_voting, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "# Train the grid search\n",
        "random_search_voting.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameter Index:\", random_search.best_index_)\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validated Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = random_search.best_estimator_\n",
        "# y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train BaggingClassifier without search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create the individual regressors without the Pipeline of scaler\n",
        "svc = SVC(kernel='linear', gamma=1, C=1)\n",
        "decision_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2)\n",
        "gaussian_NB = GaussianNB(var_smoothing=0.001)\n",
        "\n",
        "# Create the VotingClassifier with the different models\n",
        "voting_regressor = VotingClassifier(estimators=[\n",
        "    ('SVC', svc),\n",
        "    ('decision_tree', decision_tree),\n",
        "    ('gaussian_NB', gaussian_NB)\n",
        "])\n",
        "\n",
        "\n",
        "model = BaggingClassifier(estimator=voting_regressor,n_estimators=50,random_state=42)\n",
        "# model.fit(x_train, y_train)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
